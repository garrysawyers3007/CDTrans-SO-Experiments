2022-05-08 15:20:14,280 reid_baseline INFO: Namespace(config_file='configs/uda.yml', opts=['MODEL.DEVICE_ID', "('0')", 'TEST.WEIGHT', "('../logs/uda/deit_base/office-home/Art2ClipartDRI/transformer_best_model.pth')", 'DATASETS.NAMES', 'OfficeHome', 'DATASETS.NAMES2', 'OfficeHome', 'OUTPUT_DIR', '../logs/pretrain/deit_base/office-home/Art2ClipartDRI', 'DATASETS.ROOT_TRAIN_DIR', '../data/OfficeHomeDataset/Art.txt', 'DATASETS.ROOT_TRAIN_DIR2', '../data/OfficeHomeDataset/Clipart.txt', 'DATASETS.ROOT_TEST_DIR', '../data/OfficeHomeDataset/Clipart.txt', 'TEST.IMS_PER_BATCH', '32'], patch_size=1, dom_cls=False, layer_num=1)
2022-05-08 15:20:14,280 reid_baseline INFO: Loaded configuration file configs/uda.yml
2022-05-08 15:20:14,280 reid_baseline INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  PRETRAIN_PATH: '../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'transformer'
  NO_MARGIN: True
  DEVICE_ID: ('0')
  Transformer_TYPE: 'uda_vit_base_patch16_224_TransReID' #uda_vit_small_patch16_224_TransReID
  STRIDE_SIZE: [16, 16]
  BLOCK_PATTERN: '3_branches'
  TASK_TYPE: 'classify_DA'
  UDA_STAGE: 'UDA'
#  CAMERA_EMBEDDING: True
#  VIEWPOINT_EMBEDDING: True

INPUT:
  SIZE_TRAIN: [256, 256]
  SIZE_TEST: [256, 256]
  SIZE_CROP: [224, 224]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.0 # random erasing
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]

DATASETS:
  NAMES: ('OURAPI')
  ROOT_TRAIN_DIR: ('./datasets/reid_datasets/Corrected_Market1501')
  NAMES2: ('OURAPI')
  ROOT_TRAIN_DIR2: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')
  ROOT_TEST_DIR: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')

DATALOADER:
  SAMPLER: 'softmax'
  NUM_INSTANCE: 4
  NUM_WORKERS: 4

SOLVER:
  OPTIMIZER_NAME: 'SGD'
  MAX_EPOCHS: 20
  BASE_LR: 0.008
  IMS_PER_BATCH: 16
  STEPS: [40, 80]
  GAMMA: 0.
  WARMUP_FACTOR: 0.01
  WARMUP_EPOCHS: 10
  WARMUP_METHOD: 'linear'
  LARGE_FC_LR: False
  CHECKPOINT_PERIOD: 10
  LOG_PERIOD: 100
  EVAL_PERIOD: 1
  WEIGHT_DECAY:  1e-4
  WEIGHT_DECAY_BIAS: 1e-4
  BIAS_LR_FACTOR: 2

TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  RE_RANKING_TRACK: False

  WEIGHT: '../logs/trans4DA/transformer_120.pth'
  NECK_FEAT: 'after'
  FEAT_NORM: 'yes'

OUTPUT_DIR: '../logs/trans4DA'



2022-05-08 15:20:14,280 reid_baseline INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 4
  SAMPLER: softmax
DATASETS:
  NAMES: OfficeHome
  NAMES2: OfficeHome
  PLUS_NUM_ID: 100
  QUERY_MINING: False
  ROOT_TEST_DIR: ../data/OfficeHomeDataset/Clipart.txt
  ROOT_TRAIN_DIR: ../data/OfficeHomeDataset/Art.txt
  ROOT_TRAIN_DIR2: ../data/OfficeHomeDataset/Clipart.txt
INPUT:
  AA_PROB: 0.0
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]
  PROB: 0.5
  RE_PROB: 0.0
  SIZE_CROP: [224, 224]
  SIZE_TEST: [256, 256]
  SIZE_TRAIN: [256, 256]
MODEL:
  AIE_COE: 1.5
  BLOCK_PATTERN: 3_branches
  CAMERA_EMBEDDING: False
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DEVIDE_LENGTH: 4
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FC_SETTING: TransReID
  FROZEN: -1
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 1.0
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  LOCAL_F: False
  METRIC_LOSS_TYPE: triplet
  NAME: transformer
  NECK: bnneck
  NO_MARGIN: True
  NO_SHUFFLE: False
  PATCH_SHUFFLE: 2
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
  PROB: 0.0
  RECIP_LOSS: 
  STRIDE_SIZE: [16, 16]
  TASK_TYPE: classify_DA
  THRESH: 0.23
  TRIPLET_LOSS_WEIGHT: 1.0
  Transformer_TYPE: uda_vit_base_patch16_224_TransReID
  UDA_STAGE: UDA
  VIEWPOINT_EMBEDDING: False
  YIWEI_NUM: 5
  lameda: 0.5
OUTPUT_DIR: ../logs/pretrain/deit_base/office-home/Art2ClipartDRI
SOLVER:
  BASE_LR: 0.008
  BIAS_LR_FACTOR: 2
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 10
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.0
  IMS_PER_BATCH: 16
  LARGE_FC_LR: False
  LOG_PERIOD: 100
  MARGIN: 0.3
  MAX_EPOCHS: 20
  MOMENTUM: 0.9
  OPTIMIZER_NAME: SGD
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1234
  STEPS: (40, 80)
  WARMUP_EPOCHS: 10
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WITH_PSEUDO_LABEL_FILTER: False
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  FLIP_FEATS: off
  IMS_PER_BATCH: 32
  NECK_FEAT: after
  RE_RANKING: False
  RE_RANKING_TRACK: False
  WEIGHT: ../logs/uda/deit_base/office-home/Art2ClipartDRI/transformer_best_model.pth
=> Office-Home loaded
Dataset statistics:
train Art and valid is Clipart
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     2427 |         1
  valid   |    65 |     4365 |         1
  ----------------------------------------
=> Office-Home loaded
Dataset statistics:
train Clipart and valid is Clipart
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4365 |         1
  valid   |    65 |     4365 |         1
  ----------------------------------------
using Transformer_type: uda_vit_base_patch16_224_TransReID as a backbone
using stride: [16, 16], and part number is num_y14 * num_x14
using drop_path_rate is : 0.1
using aie_xishu is : 1.5
using 3branches blocks
distill need to choose right cls token in the pth
Resized position embedding: %s to %s torch.Size([1, 197, 768]) torch.Size([1, 197, 768])
Position embedding resize to height:14 width: 14
Loading pretrained ImageNet model......from ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
===========building uda transformer===========
Loading pretrained model for finetuning from ../logs/uda/deit_base/office-home/Art2ClipartDRI/transformer_best_model.pth
2022-05-08 15:20:30,335 reid_baseline.test INFO: Enter inferencing
Using 4 GPUs for inference
2022-05-08 15:24:16,564 reid_baseline.test INFO: normal accuracy 0.4449026345933562 1.3422240018844604 
2022-05-08 15:24:16,564 reid_baseline.test INFO: Classify Domain Adapatation Validation Results - In the source trained model
2022-05-08 15:24:16,565 reid_baseline.test INFO: Accuracy: 44.5%
2022-05-08 15:24:25,346 reid_baseline INFO: Namespace(config_file='configs/uda.yml', opts=['MODEL.DEVICE_ID', "('0')", 'TEST.WEIGHT', "('../logs/uda/deit_base/office-home/Art2ProductDRI/transformer_best_model.pth')", 'DATASETS.NAMES', 'OfficeHome', 'DATASETS.NAMES2', 'OfficeHome', 'OUTPUT_DIR', '../logs/pretrain/deit_base/office-home/Art2ProductDRI', 'DATASETS.ROOT_TRAIN_DIR', '../data/OfficeHomeDataset/Art.txt', 'DATASETS.ROOT_TRAIN_DIR2', '../data/OfficeHomeDataset/Product.txt', 'DATASETS.ROOT_TEST_DIR', '../data/OfficeHomeDataset/Product.txt', 'TEST.IMS_PER_BATCH', '32'], patch_size=1, dom_cls=False, layer_num=1)
2022-05-08 15:24:25,347 reid_baseline INFO: Loaded configuration file configs/uda.yml
2022-05-08 15:24:25,347 reid_baseline INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  PRETRAIN_PATH: '../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'transformer'
  NO_MARGIN: True
  DEVICE_ID: ('0')
  Transformer_TYPE: 'uda_vit_base_patch16_224_TransReID' #uda_vit_small_patch16_224_TransReID
  STRIDE_SIZE: [16, 16]
  BLOCK_PATTERN: '3_branches'
  TASK_TYPE: 'classify_DA'
  UDA_STAGE: 'UDA'
#  CAMERA_EMBEDDING: True
#  VIEWPOINT_EMBEDDING: True

INPUT:
  SIZE_TRAIN: [256, 256]
  SIZE_TEST: [256, 256]
  SIZE_CROP: [224, 224]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.0 # random erasing
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]

DATASETS:
  NAMES: ('OURAPI')
  ROOT_TRAIN_DIR: ('./datasets/reid_datasets/Corrected_Market1501')
  NAMES2: ('OURAPI')
  ROOT_TRAIN_DIR2: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')
  ROOT_TEST_DIR: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')

DATALOADER:
  SAMPLER: 'softmax'
  NUM_INSTANCE: 4
  NUM_WORKERS: 4

SOLVER:
  OPTIMIZER_NAME: 'SGD'
  MAX_EPOCHS: 20
  BASE_LR: 0.008
  IMS_PER_BATCH: 16
  STEPS: [40, 80]
  GAMMA: 0.
  WARMUP_FACTOR: 0.01
  WARMUP_EPOCHS: 10
  WARMUP_METHOD: 'linear'
  LARGE_FC_LR: False
  CHECKPOINT_PERIOD: 10
  LOG_PERIOD: 100
  EVAL_PERIOD: 1
  WEIGHT_DECAY:  1e-4
  WEIGHT_DECAY_BIAS: 1e-4
  BIAS_LR_FACTOR: 2

TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  RE_RANKING_TRACK: False

  WEIGHT: '../logs/trans4DA/transformer_120.pth'
  NECK_FEAT: 'after'
  FEAT_NORM: 'yes'

OUTPUT_DIR: '../logs/trans4DA'



2022-05-08 15:24:25,348 reid_baseline INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 4
  SAMPLER: softmax
DATASETS:
  NAMES: OfficeHome
  NAMES2: OfficeHome
  PLUS_NUM_ID: 100
  QUERY_MINING: False
  ROOT_TEST_DIR: ../data/OfficeHomeDataset/Product.txt
  ROOT_TRAIN_DIR: ../data/OfficeHomeDataset/Art.txt
  ROOT_TRAIN_DIR2: ../data/OfficeHomeDataset/Product.txt
INPUT:
  AA_PROB: 0.0
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]
  PROB: 0.5
  RE_PROB: 0.0
  SIZE_CROP: [224, 224]
  SIZE_TEST: [256, 256]
  SIZE_TRAIN: [256, 256]
MODEL:
  AIE_COE: 1.5
  BLOCK_PATTERN: 3_branches
  CAMERA_EMBEDDING: False
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DEVIDE_LENGTH: 4
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FC_SETTING: TransReID
  FROZEN: -1
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 1.0
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  LOCAL_F: False
  METRIC_LOSS_TYPE: triplet
  NAME: transformer
  NECK: bnneck
  NO_MARGIN: True
  NO_SHUFFLE: False
  PATCH_SHUFFLE: 2
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
  PROB: 0.0
  RECIP_LOSS: 
  STRIDE_SIZE: [16, 16]
  TASK_TYPE: classify_DA
  THRESH: 0.23
  TRIPLET_LOSS_WEIGHT: 1.0
  Transformer_TYPE: uda_vit_base_patch16_224_TransReID
  UDA_STAGE: UDA
  VIEWPOINT_EMBEDDING: False
  YIWEI_NUM: 5
  lameda: 0.5
OUTPUT_DIR: ../logs/pretrain/deit_base/office-home/Art2ProductDRI
SOLVER:
  BASE_LR: 0.008
  BIAS_LR_FACTOR: 2
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 10
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.0
  IMS_PER_BATCH: 16
  LARGE_FC_LR: False
  LOG_PERIOD: 100
  MARGIN: 0.3
  MAX_EPOCHS: 20
  MOMENTUM: 0.9
  OPTIMIZER_NAME: SGD
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1234
  STEPS: (40, 80)
  WARMUP_EPOCHS: 10
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WITH_PSEUDO_LABEL_FILTER: False
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  FLIP_FEATS: off
  IMS_PER_BATCH: 32
  NECK_FEAT: after
  RE_RANKING: False
  RE_RANKING_TRACK: False
  WEIGHT: ../logs/uda/deit_base/office-home/Art2ProductDRI/transformer_best_model.pth
=> Office-Home loaded
Dataset statistics:
train Art and valid is Product
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     2427 |         1
  valid   |    65 |     4439 |         1
  ----------------------------------------
=> Office-Home loaded
Dataset statistics:
train Product and valid is Product
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4439 |         1
  valid   |    65 |     4439 |         1
  ----------------------------------------
using Transformer_type: uda_vit_base_patch16_224_TransReID as a backbone
using stride: [16, 16], and part number is num_y14 * num_x14
using drop_path_rate is : 0.1
using aie_xishu is : 1.5
using 3branches blocks
distill need to choose right cls token in the pth
Resized position embedding: %s to %s torch.Size([1, 197, 768]) torch.Size([1, 197, 768])
Position embedding resize to height:14 width: 14
Loading pretrained ImageNet model......from ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
===========building uda transformer===========
Loading pretrained model for finetuning from ../logs/uda/deit_base/office-home/Art2ProductDRI/transformer_best_model.pth
2022-05-08 15:24:42,651 reid_baseline.test INFO: Enter inferencing
Using 4 GPUs for inference
2022-05-08 15:28:55,356 reid_baseline.test INFO: normal accuracy 0.5334534805136292 1.206357717514038 
2022-05-08 15:28:55,359 reid_baseline.test INFO: Classify Domain Adapatation Validation Results - In the source trained model
2022-05-08 15:28:55,359 reid_baseline.test INFO: Accuracy: 53.3%
2022-05-08 15:29:04,499 reid_baseline INFO: Namespace(config_file='configs/uda.yml', opts=['MODEL.DEVICE_ID', "('0')", 'TEST.WEIGHT', "('../logs/uda/deit_base/office-home/Art2Real_WorldDRI/transformer_best_model.pth')", 'DATASETS.NAMES', 'OfficeHome', 'DATASETS.NAMES2', 'OfficeHome', 'OUTPUT_DIR', '../logs/pretrain/deit_base/office-home/Art2Real_WorldDRI', 'DATASETS.ROOT_TRAIN_DIR', '../data/OfficeHomeDataset/Art.txt', 'DATASETS.ROOT_TRAIN_DIR2', '../data/OfficeHomeDataset/Real_World.txt', 'DATASETS.ROOT_TEST_DIR', '../data/OfficeHomeDataset/Real_World.txt', 'TEST.IMS_PER_BATCH', '32'], patch_size=1, dom_cls=False, layer_num=1)
2022-05-08 15:29:04,500 reid_baseline INFO: Loaded configuration file configs/uda.yml
2022-05-08 15:29:04,500 reid_baseline INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  PRETRAIN_PATH: '../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'transformer'
  NO_MARGIN: True
  DEVICE_ID: ('0')
  Transformer_TYPE: 'uda_vit_base_patch16_224_TransReID' #uda_vit_small_patch16_224_TransReID
  STRIDE_SIZE: [16, 16]
  BLOCK_PATTERN: '3_branches'
  TASK_TYPE: 'classify_DA'
  UDA_STAGE: 'UDA'
#  CAMERA_EMBEDDING: True
#  VIEWPOINT_EMBEDDING: True

INPUT:
  SIZE_TRAIN: [256, 256]
  SIZE_TEST: [256, 256]
  SIZE_CROP: [224, 224]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.0 # random erasing
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]

DATASETS:
  NAMES: ('OURAPI')
  ROOT_TRAIN_DIR: ('./datasets/reid_datasets/Corrected_Market1501')
  NAMES2: ('OURAPI')
  ROOT_TRAIN_DIR2: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')
  ROOT_TEST_DIR: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')

DATALOADER:
  SAMPLER: 'softmax'
  NUM_INSTANCE: 4
  NUM_WORKERS: 4

SOLVER:
  OPTIMIZER_NAME: 'SGD'
  MAX_EPOCHS: 20
  BASE_LR: 0.008
  IMS_PER_BATCH: 16
  STEPS: [40, 80]
  GAMMA: 0.
  WARMUP_FACTOR: 0.01
  WARMUP_EPOCHS: 10
  WARMUP_METHOD: 'linear'
  LARGE_FC_LR: False
  CHECKPOINT_PERIOD: 10
  LOG_PERIOD: 100
  EVAL_PERIOD: 1
  WEIGHT_DECAY:  1e-4
  WEIGHT_DECAY_BIAS: 1e-4
  BIAS_LR_FACTOR: 2

TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  RE_RANKING_TRACK: False

  WEIGHT: '../logs/trans4DA/transformer_120.pth'
  NECK_FEAT: 'after'
  FEAT_NORM: 'yes'

OUTPUT_DIR: '../logs/trans4DA'



2022-05-08 15:29:04,500 reid_baseline INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 4
  SAMPLER: softmax
DATASETS:
  NAMES: OfficeHome
  NAMES2: OfficeHome
  PLUS_NUM_ID: 100
  QUERY_MINING: False
  ROOT_TEST_DIR: ../data/OfficeHomeDataset/Real_World.txt
  ROOT_TRAIN_DIR: ../data/OfficeHomeDataset/Art.txt
  ROOT_TRAIN_DIR2: ../data/OfficeHomeDataset/Real_World.txt
INPUT:
  AA_PROB: 0.0
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]
  PROB: 0.5
  RE_PROB: 0.0
  SIZE_CROP: [224, 224]
  SIZE_TEST: [256, 256]
  SIZE_TRAIN: [256, 256]
MODEL:
  AIE_COE: 1.5
  BLOCK_PATTERN: 3_branches
  CAMERA_EMBEDDING: False
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DEVIDE_LENGTH: 4
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FC_SETTING: TransReID
  FROZEN: -1
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 1.0
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  LOCAL_F: False
  METRIC_LOSS_TYPE: triplet
  NAME: transformer
  NECK: bnneck
  NO_MARGIN: True
  NO_SHUFFLE: False
  PATCH_SHUFFLE: 2
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
  PROB: 0.0
  RECIP_LOSS: 
  STRIDE_SIZE: [16, 16]
  TASK_TYPE: classify_DA
  THRESH: 0.23
  TRIPLET_LOSS_WEIGHT: 1.0
  Transformer_TYPE: uda_vit_base_patch16_224_TransReID
  UDA_STAGE: UDA
  VIEWPOINT_EMBEDDING: False
  YIWEI_NUM: 5
  lameda: 0.5
OUTPUT_DIR: ../logs/pretrain/deit_base/office-home/Art2Real_WorldDRI
SOLVER:
  BASE_LR: 0.008
  BIAS_LR_FACTOR: 2
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 10
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.0
  IMS_PER_BATCH: 16
  LARGE_FC_LR: False
  LOG_PERIOD: 100
  MARGIN: 0.3
  MAX_EPOCHS: 20
  MOMENTUM: 0.9
  OPTIMIZER_NAME: SGD
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1234
  STEPS: (40, 80)
  WARMUP_EPOCHS: 10
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WITH_PSEUDO_LABEL_FILTER: False
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  FLIP_FEATS: off
  IMS_PER_BATCH: 32
  NECK_FEAT: after
  RE_RANKING: False
  RE_RANKING_TRACK: False
  WEIGHT: ../logs/uda/deit_base/office-home/Art2Real_WorldDRI/transformer_best_model.pth
=> Office-Home loaded
Dataset statistics:
train Art and valid is Real_World
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     2427 |         1
  valid   |    65 |     4357 |         1
  ----------------------------------------
=> Office-Home loaded
Dataset statistics:
train Real_World and valid is Real_World
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4357 |         1
  valid   |    65 |     4357 |         1
  ----------------------------------------
using Transformer_type: uda_vit_base_patch16_224_TransReID as a backbone
using stride: [16, 16], and part number is num_y14 * num_x14
using drop_path_rate is : 0.1
using aie_xishu is : 1.5
using 3branches blocks
distill need to choose right cls token in the pth
Resized position embedding: %s to %s torch.Size([1, 197, 768]) torch.Size([1, 197, 768])
Position embedding resize to height:14 width: 14
Loading pretrained ImageNet model......from ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
===========building uda transformer===========
Loading pretrained model for finetuning from ../logs/uda/deit_base/office-home/Art2Real_WorldDRI/transformer_best_model.pth
2022-05-08 15:29:21,147 reid_baseline.test INFO: Enter inferencing
Using 4 GPUs for inference
2022-05-08 15:39:09,517 reid_baseline.test INFO: normal accuracy 0.6313977507459261 0.999958872795105 
2022-05-08 15:39:09,517 reid_baseline.test INFO: Classify Domain Adapatation Validation Results - In the source trained model
2022-05-08 15:39:09,517 reid_baseline.test INFO: Accuracy: 63.1%
2022-05-08 15:39:18,840 reid_baseline INFO: Namespace(config_file='configs/uda.yml', opts=['MODEL.DEVICE_ID', "('0')", 'TEST.WEIGHT', "('../logs/uda/deit_base/office-home/Clipart2ArtDRI/transformer_best_model.pth')", 'DATASETS.NAMES', 'OfficeHome', 'DATASETS.NAMES2', 'OfficeHome', 'OUTPUT_DIR', '../logs/pretrain/deit_base/office-home/Clipart2ArtDRI', 'DATASETS.ROOT_TRAIN_DIR', '../data/OfficeHomeDataset/Clipart.txt', 'DATASETS.ROOT_TRAIN_DIR2', '../data/OfficeHomeDataset/Art.txt', 'DATASETS.ROOT_TEST_DIR', '../data/OfficeHomeDataset/Art.txt', 'TEST.IMS_PER_BATCH', '32'], patch_size=1, dom_cls=False, layer_num=1)
2022-05-08 15:39:18,840 reid_baseline INFO: Loaded configuration file configs/uda.yml
2022-05-08 15:39:18,841 reid_baseline INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  PRETRAIN_PATH: '../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'transformer'
  NO_MARGIN: True
  DEVICE_ID: ('0')
  Transformer_TYPE: 'uda_vit_base_patch16_224_TransReID' #uda_vit_small_patch16_224_TransReID
  STRIDE_SIZE: [16, 16]
  BLOCK_PATTERN: '3_branches'
  TASK_TYPE: 'classify_DA'
  UDA_STAGE: 'UDA'
#  CAMERA_EMBEDDING: True
#  VIEWPOINT_EMBEDDING: True

INPUT:
  SIZE_TRAIN: [256, 256]
  SIZE_TEST: [256, 256]
  SIZE_CROP: [224, 224]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.0 # random erasing
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]

DATASETS:
  NAMES: ('OURAPI')
  ROOT_TRAIN_DIR: ('./datasets/reid_datasets/Corrected_Market1501')
  NAMES2: ('OURAPI')
  ROOT_TRAIN_DIR2: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')
  ROOT_TEST_DIR: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')

DATALOADER:
  SAMPLER: 'softmax'
  NUM_INSTANCE: 4
  NUM_WORKERS: 4

SOLVER:
  OPTIMIZER_NAME: 'SGD'
  MAX_EPOCHS: 20
  BASE_LR: 0.008
  IMS_PER_BATCH: 16
  STEPS: [40, 80]
  GAMMA: 0.
  WARMUP_FACTOR: 0.01
  WARMUP_EPOCHS: 10
  WARMUP_METHOD: 'linear'
  LARGE_FC_LR: False
  CHECKPOINT_PERIOD: 10
  LOG_PERIOD: 100
  EVAL_PERIOD: 1
  WEIGHT_DECAY:  1e-4
  WEIGHT_DECAY_BIAS: 1e-4
  BIAS_LR_FACTOR: 2

TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  RE_RANKING_TRACK: False

  WEIGHT: '../logs/trans4DA/transformer_120.pth'
  NECK_FEAT: 'after'
  FEAT_NORM: 'yes'

OUTPUT_DIR: '../logs/trans4DA'



2022-05-08 15:39:18,841 reid_baseline INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 4
  SAMPLER: softmax
DATASETS:
  NAMES: OfficeHome
  NAMES2: OfficeHome
  PLUS_NUM_ID: 100
  QUERY_MINING: False
  ROOT_TEST_DIR: ../data/OfficeHomeDataset/Art.txt
  ROOT_TRAIN_DIR: ../data/OfficeHomeDataset/Clipart.txt
  ROOT_TRAIN_DIR2: ../data/OfficeHomeDataset/Art.txt
INPUT:
  AA_PROB: 0.0
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]
  PROB: 0.5
  RE_PROB: 0.0
  SIZE_CROP: [224, 224]
  SIZE_TEST: [256, 256]
  SIZE_TRAIN: [256, 256]
MODEL:
  AIE_COE: 1.5
  BLOCK_PATTERN: 3_branches
  CAMERA_EMBEDDING: False
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DEVIDE_LENGTH: 4
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FC_SETTING: TransReID
  FROZEN: -1
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 1.0
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  LOCAL_F: False
  METRIC_LOSS_TYPE: triplet
  NAME: transformer
  NECK: bnneck
  NO_MARGIN: True
  NO_SHUFFLE: False
  PATCH_SHUFFLE: 2
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
  PROB: 0.0
  RECIP_LOSS: 
  STRIDE_SIZE: [16, 16]
  TASK_TYPE: classify_DA
  THRESH: 0.23
  TRIPLET_LOSS_WEIGHT: 1.0
  Transformer_TYPE: uda_vit_base_patch16_224_TransReID
  UDA_STAGE: UDA
  VIEWPOINT_EMBEDDING: False
  YIWEI_NUM: 5
  lameda: 0.5
OUTPUT_DIR: ../logs/pretrain/deit_base/office-home/Clipart2ArtDRI
SOLVER:
  BASE_LR: 0.008
  BIAS_LR_FACTOR: 2
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 10
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.0
  IMS_PER_BATCH: 16
  LARGE_FC_LR: False
  LOG_PERIOD: 100
  MARGIN: 0.3
  MAX_EPOCHS: 20
  MOMENTUM: 0.9
  OPTIMIZER_NAME: SGD
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1234
  STEPS: (40, 80)
  WARMUP_EPOCHS: 10
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WITH_PSEUDO_LABEL_FILTER: False
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  FLIP_FEATS: off
  IMS_PER_BATCH: 32
  NECK_FEAT: after
  RE_RANKING: False
  RE_RANKING_TRACK: False
  WEIGHT: ../logs/uda/deit_base/office-home/Clipart2ArtDRI/transformer_best_model.pth
=> Office-Home loaded
Dataset statistics:
train Clipart and valid is Art
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4365 |         1
  valid   |    65 |     2427 |         1
  ----------------------------------------
=> Office-Home loaded
Dataset statistics:
train Art and valid is Art
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     2427 |         1
  valid   |    65 |     2427 |         1
  ----------------------------------------
using Transformer_type: uda_vit_base_patch16_224_TransReID as a backbone
using stride: [16, 16], and part number is num_y14 * num_x14
using drop_path_rate is : 0.1
using aie_xishu is : 1.5
using 3branches blocks
distill need to choose right cls token in the pth
Resized position embedding: %s to %s torch.Size([1, 197, 768]) torch.Size([1, 197, 768])
Position embedding resize to height:14 width: 14
Loading pretrained ImageNet model......from ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
===========building uda transformer===========
Loading pretrained model for finetuning from ../logs/uda/deit_base/office-home/Clipart2ArtDRI/transformer_best_model.pth
2022-05-08 15:39:35,086 reid_baseline.test INFO: Enter inferencing
Using 4 GPUs for inference
2022-05-08 15:42:42,444 reid_baseline.test INFO: normal accuracy 0.6798516687268232 0.88468998670578 
2022-05-08 15:42:42,444 reid_baseline.test INFO: Classify Domain Adapatation Validation Results - In the source trained model
2022-05-08 15:42:42,444 reid_baseline.test INFO: Accuracy: 68.0%
2022-05-08 15:42:51,030 reid_baseline INFO: Namespace(config_file='configs/uda.yml', opts=['MODEL.DEVICE_ID', "('0')", 'TEST.WEIGHT', "('../logs/uda/deit_base/office-home/Clipart2ProductDRI/transformer_best_model.pth')", 'DATASETS.NAMES', 'OfficeHome', 'DATASETS.NAMES2', 'OfficeHome', 'OUTPUT_DIR', '../logs/pretrain/deit_base/office-home/Clipart2ProductDRI', 'DATASETS.ROOT_TRAIN_DIR', '../data/OfficeHomeDataset/Clipart.txt', 'DATASETS.ROOT_TRAIN_DIR2', '../data/OfficeHomeDataset/Product.txt', 'DATASETS.ROOT_TEST_DIR', '../data/OfficeHomeDataset/Product.txt', 'TEST.IMS_PER_BATCH', '32'], patch_size=1, dom_cls=False, layer_num=1)
2022-05-08 15:42:51,030 reid_baseline INFO: Loaded configuration file configs/uda.yml
2022-05-08 15:42:51,031 reid_baseline INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  PRETRAIN_PATH: '../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'transformer'
  NO_MARGIN: True
  DEVICE_ID: ('0')
  Transformer_TYPE: 'uda_vit_base_patch16_224_TransReID' #uda_vit_small_patch16_224_TransReID
  STRIDE_SIZE: [16, 16]
  BLOCK_PATTERN: '3_branches'
  TASK_TYPE: 'classify_DA'
  UDA_STAGE: 'UDA'
#  CAMERA_EMBEDDING: True
#  VIEWPOINT_EMBEDDING: True

INPUT:
  SIZE_TRAIN: [256, 256]
  SIZE_TEST: [256, 256]
  SIZE_CROP: [224, 224]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.0 # random erasing
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]

DATASETS:
  NAMES: ('OURAPI')
  ROOT_TRAIN_DIR: ('./datasets/reid_datasets/Corrected_Market1501')
  NAMES2: ('OURAPI')
  ROOT_TRAIN_DIR2: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')
  ROOT_TEST_DIR: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')

DATALOADER:
  SAMPLER: 'softmax'
  NUM_INSTANCE: 4
  NUM_WORKERS: 4

SOLVER:
  OPTIMIZER_NAME: 'SGD'
  MAX_EPOCHS: 20
  BASE_LR: 0.008
  IMS_PER_BATCH: 16
  STEPS: [40, 80]
  GAMMA: 0.
  WARMUP_FACTOR: 0.01
  WARMUP_EPOCHS: 10
  WARMUP_METHOD: 'linear'
  LARGE_FC_LR: False
  CHECKPOINT_PERIOD: 10
  LOG_PERIOD: 100
  EVAL_PERIOD: 1
  WEIGHT_DECAY:  1e-4
  WEIGHT_DECAY_BIAS: 1e-4
  BIAS_LR_FACTOR: 2

TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  RE_RANKING_TRACK: False

  WEIGHT: '../logs/trans4DA/transformer_120.pth'
  NECK_FEAT: 'after'
  FEAT_NORM: 'yes'

OUTPUT_DIR: '../logs/trans4DA'



2022-05-08 15:42:51,031 reid_baseline INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 4
  SAMPLER: softmax
DATASETS:
  NAMES: OfficeHome
  NAMES2: OfficeHome
  PLUS_NUM_ID: 100
  QUERY_MINING: False
  ROOT_TEST_DIR: ../data/OfficeHomeDataset/Product.txt
  ROOT_TRAIN_DIR: ../data/OfficeHomeDataset/Clipart.txt
  ROOT_TRAIN_DIR2: ../data/OfficeHomeDataset/Product.txt
INPUT:
  AA_PROB: 0.0
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]
  PROB: 0.5
  RE_PROB: 0.0
  SIZE_CROP: [224, 224]
  SIZE_TEST: [256, 256]
  SIZE_TRAIN: [256, 256]
MODEL:
  AIE_COE: 1.5
  BLOCK_PATTERN: 3_branches
  CAMERA_EMBEDDING: False
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DEVIDE_LENGTH: 4
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FC_SETTING: TransReID
  FROZEN: -1
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 1.0
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  LOCAL_F: False
  METRIC_LOSS_TYPE: triplet
  NAME: transformer
  NECK: bnneck
  NO_MARGIN: True
  NO_SHUFFLE: False
  PATCH_SHUFFLE: 2
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
  PROB: 0.0
  RECIP_LOSS: 
  STRIDE_SIZE: [16, 16]
  TASK_TYPE: classify_DA
  THRESH: 0.23
  TRIPLET_LOSS_WEIGHT: 1.0
  Transformer_TYPE: uda_vit_base_patch16_224_TransReID
  UDA_STAGE: UDA
  VIEWPOINT_EMBEDDING: False
  YIWEI_NUM: 5
  lameda: 0.5
OUTPUT_DIR: ../logs/pretrain/deit_base/office-home/Clipart2ProductDRI
SOLVER:
  BASE_LR: 0.008
  BIAS_LR_FACTOR: 2
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 10
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.0
  IMS_PER_BATCH: 16
  LARGE_FC_LR: False
  LOG_PERIOD: 100
  MARGIN: 0.3
  MAX_EPOCHS: 20
  MOMENTUM: 0.9
  OPTIMIZER_NAME: SGD
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1234
  STEPS: (40, 80)
  WARMUP_EPOCHS: 10
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WITH_PSEUDO_LABEL_FILTER: False
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  FLIP_FEATS: off
  IMS_PER_BATCH: 32
  NECK_FEAT: after
  RE_RANKING: False
  RE_RANKING_TRACK: False
  WEIGHT: ../logs/uda/deit_base/office-home/Clipart2ProductDRI/transformer_best_model.pth
=> Office-Home loaded
Dataset statistics:
train Clipart and valid is Product
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4365 |         1
  valid   |    65 |     4439 |         1
  ----------------------------------------
=> Office-Home loaded
Dataset statistics:
train Product and valid is Product
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4439 |         1
  valid   |    65 |     4439 |         1
  ----------------------------------------
using Transformer_type: uda_vit_base_patch16_224_TransReID as a backbone
using stride: [16, 16], and part number is num_y14 * num_x14
using drop_path_rate is : 0.1
using aie_xishu is : 1.5
using 3branches blocks
distill need to choose right cls token in the pth
Resized position embedding: %s to %s torch.Size([1, 197, 768]) torch.Size([1, 197, 768])
Position embedding resize to height:14 width: 14
Loading pretrained ImageNet model......from ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
===========building uda transformer===========
Loading pretrained model for finetuning from ../logs/uda/deit_base/office-home/Clipart2ProductDRI/transformer_best_model.pth
2022-05-08 15:43:06,969 reid_baseline.test INFO: Enter inferencing
Using 4 GPUs for inference
2022-05-08 15:47:01,300 reid_baseline.test INFO: normal accuracy 0.6958774498760982 0.7363548278808594 
2022-05-08 15:47:01,301 reid_baseline.test INFO: Classify Domain Adapatation Validation Results - In the source trained model
2022-05-08 15:47:01,301 reid_baseline.test INFO: Accuracy: 69.6%
2022-05-08 15:47:09,233 reid_baseline INFO: Namespace(config_file='configs/uda.yml', opts=['MODEL.DEVICE_ID', "('0')", 'TEST.WEIGHT', "('../logs/uda/deit_base/office-home/Clipart2Real_WorldDRI/transformer_best_model.pth')", 'DATASETS.NAMES', 'OfficeHome', 'DATASETS.NAMES2', 'OfficeHome', 'OUTPUT_DIR', '../logs/pretrain/deit_base/office-home/Clipart2Real_WorldDRI', 'DATASETS.ROOT_TRAIN_DIR', '../data/OfficeHomeDataset/Clipart.txt', 'DATASETS.ROOT_TRAIN_DIR2', '../data/OfficeHomeDataset/Real_World.txt', 'DATASETS.ROOT_TEST_DIR', '../data/OfficeHomeDataset/Real_World.txt', 'TEST.IMS_PER_BATCH', '32'], patch_size=1, dom_cls=False, layer_num=1)
2022-05-08 15:47:09,233 reid_baseline INFO: Loaded configuration file configs/uda.yml
2022-05-08 15:47:09,233 reid_baseline INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  PRETRAIN_PATH: '../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'transformer'
  NO_MARGIN: True
  DEVICE_ID: ('0')
  Transformer_TYPE: 'uda_vit_base_patch16_224_TransReID' #uda_vit_small_patch16_224_TransReID
  STRIDE_SIZE: [16, 16]
  BLOCK_PATTERN: '3_branches'
  TASK_TYPE: 'classify_DA'
  UDA_STAGE: 'UDA'
#  CAMERA_EMBEDDING: True
#  VIEWPOINT_EMBEDDING: True

INPUT:
  SIZE_TRAIN: [256, 256]
  SIZE_TEST: [256, 256]
  SIZE_CROP: [224, 224]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.0 # random erasing
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]

DATASETS:
  NAMES: ('OURAPI')
  ROOT_TRAIN_DIR: ('./datasets/reid_datasets/Corrected_Market1501')
  NAMES2: ('OURAPI')
  ROOT_TRAIN_DIR2: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')
  ROOT_TEST_DIR: ('./datasets/reid_datasets/Refined_DukeMTMC_reID')

DATALOADER:
  SAMPLER: 'softmax'
  NUM_INSTANCE: 4
  NUM_WORKERS: 4

SOLVER:
  OPTIMIZER_NAME: 'SGD'
  MAX_EPOCHS: 20
  BASE_LR: 0.008
  IMS_PER_BATCH: 16
  STEPS: [40, 80]
  GAMMA: 0.
  WARMUP_FACTOR: 0.01
  WARMUP_EPOCHS: 10
  WARMUP_METHOD: 'linear'
  LARGE_FC_LR: False
  CHECKPOINT_PERIOD: 10
  LOG_PERIOD: 100
  EVAL_PERIOD: 1
  WEIGHT_DECAY:  1e-4
  WEIGHT_DECAY_BIAS: 1e-4
  BIAS_LR_FACTOR: 2

TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  RE_RANKING_TRACK: False

  WEIGHT: '../logs/trans4DA/transformer_120.pth'
  NECK_FEAT: 'after'
  FEAT_NORM: 'yes'

OUTPUT_DIR: '../logs/trans4DA'



2022-05-08 15:47:09,234 reid_baseline INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 4
  SAMPLER: softmax
DATASETS:
  NAMES: OfficeHome
  NAMES2: OfficeHome
  PLUS_NUM_ID: 100
  QUERY_MINING: False
  ROOT_TEST_DIR: ../data/OfficeHomeDataset/Real_World.txt
  ROOT_TRAIN_DIR: ../data/OfficeHomeDataset/Clipart.txt
  ROOT_TRAIN_DIR2: ../data/OfficeHomeDataset/Real_World.txt
INPUT:
  AA_PROB: 0.0
  PADDING: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]
  PROB: 0.5
  RE_PROB: 0.0
  SIZE_CROP: [224, 224]
  SIZE_TEST: [256, 256]
  SIZE_TRAIN: [256, 256]
MODEL:
  AIE_COE: 1.5
  BLOCK_PATTERN: 3_branches
  CAMERA_EMBEDDING: False
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DEVIDE_LENGTH: 4
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FC_SETTING: TransReID
  FROZEN: -1
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 1.0
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  LOCAL_F: False
  METRIC_LOSS_TYPE: triplet
  NAME: transformer
  NECK: bnneck
  NO_MARGIN: True
  NO_SHUFFLE: False
  PATCH_SHUFFLE: 2
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
  PROB: 0.0
  RECIP_LOSS: 
  STRIDE_SIZE: [16, 16]
  TASK_TYPE: classify_DA
  THRESH: 0.23
  TRIPLET_LOSS_WEIGHT: 1.0
  Transformer_TYPE: uda_vit_base_patch16_224_TransReID
  UDA_STAGE: UDA
  VIEWPOINT_EMBEDDING: False
  YIWEI_NUM: 5
  lameda: 0.5
OUTPUT_DIR: ../logs/pretrain/deit_base/office-home/Clipart2Real_WorldDRI
SOLVER:
  BASE_LR: 0.008
  BIAS_LR_FACTOR: 2
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 10
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.0
  IMS_PER_BATCH: 16
  LARGE_FC_LR: False
  LOG_PERIOD: 100
  MARGIN: 0.3
  MAX_EPOCHS: 20
  MOMENTUM: 0.9
  OPTIMIZER_NAME: SGD
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1234
  STEPS: (40, 80)
  WARMUP_EPOCHS: 10
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WITH_PSEUDO_LABEL_FILTER: False
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  FLIP_FEATS: off
  IMS_PER_BATCH: 32
  NECK_FEAT: after
  RE_RANKING: False
  RE_RANKING_TRACK: False
  WEIGHT: ../logs/uda/deit_base/office-home/Clipart2Real_WorldDRI/transformer_best_model.pth
=> Office-Home loaded
Dataset statistics:
train Clipart and valid is Real_World
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4365 |         1
  valid   |    65 |     4357 |         1
  ----------------------------------------
=> Office-Home loaded
Dataset statistics:
train Real_World and valid is Real_World
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train   |    65 |     4357 |         1
  valid   |    65 |     4357 |         1
  ----------------------------------------
using Transformer_type: uda_vit_base_patch16_224_TransReID as a backbone
using stride: [16, 16], and part number is num_y14 * num_x14
using drop_path_rate is : 0.1
using aie_xishu is : 1.5
using 3branches blocks
distill need to choose right cls token in the pth
Resized position embedding: %s to %s torch.Size([1, 197, 768]) torch.Size([1, 197, 768])
Position embedding resize to height:14 width: 14
Loading pretrained ImageNet model......from ../data/pretrainModel/deit_base_distilled_patch16_224-df68dfff.pth
===========building uda transformer===========
Loading pretrained model for finetuning from ../logs/uda/deit_base/office-home/Clipart2Real_WorldDRI/transformer_best_model.pth
2022-05-08 15:47:27,175 reid_baseline.test INFO: Enter inferencing
Using 4 GPUs for inference
2022-05-08 15:57:09,276 reid_baseline.test INFO: normal accuracy 0.7248106495294928 0.7473446130752563 
2022-05-08 15:57:09,276 reid_baseline.test INFO: Classify Domain Adapatation Validation Results - In the source trained model
2022-05-08 15:57:09,276 reid_baseline.test INFO: Accuracy: 72.5%
